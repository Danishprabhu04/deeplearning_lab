{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8fffaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-12 00:38:30.023678: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-12 00:38:30.033469: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-12 00:38:30.388259: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-12 00:38:31.893403: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-12 00:38:31.894715: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating sequences...\n",
      "Number of sequences: 1115294\n",
      "Converting to numerical form...\n",
      "X shape: (1115294, 99)\n",
      "y shape: (1115294, 65)\n",
      "Vocabulary size: 65\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "path_to_file = tf.keras.utils.get_file(\"shakespeare.txt\", \"input.txt\")\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "# Preprocess data\n",
    "chars = sorted(set(text))\n",
    "char2idx = {c: i for i, c in enumerate(chars)}\n",
    "idx2char = np.array(chars)\n",
    "\n",
    "# Prepare training data\n",
    "seq_length = 100\n",
    "step = 1  # Step size for sliding window\n",
    "sequences = []\n",
    "next_chars = []\n",
    "\n",
    "# Create sequences more efficiently\n",
    "print(\"Creating sequences...\")\n",
    "for i in range(0, len(text) - seq_length, step):\n",
    "    sequences.append(text[i:i + seq_length])\n",
    "    next_chars.append(text[i + seq_length])\n",
    "\n",
    "print(f\"Number of sequences: {len(sequences)}\")\n",
    "\n",
    "# Convert to numerical form\n",
    "X = np.zeros((len(sequences), seq_length-1), dtype=np.int32)\n",
    "y = np.zeros(len(sequences), dtype=np.int32)\n",
    "\n",
    "print(\"Converting to numerical form...\")\n",
    "for i, sequence in enumerate(sequences):\n",
    "    # Convert input sequence\n",
    "    for t, char in enumerate(sequence[:-1]):  # All but last char\n",
    "        X[i, t] = char2idx[char]\n",
    "    # Convert target char\n",
    "    y[i] = char2idx[next_chars[i]]\n",
    "\n",
    "# Convert y to one-hot encoding\n",
    "y = to_categorical(y, num_classes=len(chars))\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"Vocabulary size: {len(chars)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d454419",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danish/Projects/projects/deeplearning/.venv/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752260931.312888   11210 cuda_executor.cc:1309] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1752260931.318455   11210 gpu_device.cc:2342] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8714/8714\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2258s\u001b[0m 259ms/step - accuracy: 0.3179 - loss: 2.4313\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7c2b862d6c90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build LSTM model\n",
    "model = tf.keras.Sequential([\n",
    "tf.keras.layers.Embedding(len(chars), 64, input_length=seq_length-1),\n",
    "tf.keras.layers.LSTM(256, return_sequences=True),\n",
    "\n",
    "tf.keras.layers.LSTM(256),\n",
    "tf.keras.layers.Dense(len(chars), activation='softmax')\n",
    "])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=1, batch_size=128)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
